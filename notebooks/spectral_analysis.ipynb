{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acoustic Well Sensing\n",
    "\n",
    "The data in this notebook comes from the job depicted in this screenshot, where we can see that offset well communication is happening because the offset wells are going up in pressure as the pressure increases in the well that is being completed.  In this case the offset wells are on a different pad ~1/2 mile away. We see communication in the closest wellbore first, and the 2nd closest wellbore 2nd (delayed poroelastic response). \n",
    "\n",
    "![example communication](images/communication_example.png)\n",
    "\n",
    "### Events to detect\n",
    " * start of pumping down the perf guns and plugs\n",
    " * end of pumping down the perf guns and plugs\n",
    " * firing off perf guns\n",
    " * start of frac stage\n",
    " * detect steep pressurization step in the stage\n",
    " * end of frac stage\n",
    " * pressurizing to create fractures\n",
    " * fractures occurring on active fracking well measuring on active fracking well\n",
    " * fractures occuring on active fracking well measuring on offset well\n",
    " * detecting signs of well communication\n",
    " * detecting communication correlation\n",
    " * Detect gear shift (false positive, looks alot like the \"pops\" when we are fracking, only occurs early in stage\n",
    "\n",
    "### Goal \n",
    " * produce a fracture report in near real-time\n",
    "     - log every detected fracture with a timestamp\n",
    "     - characterize their magnitude, count, detect a seam that cracks rapidly in succession\n",
    " * detect early signs of communication using dynamic sensors before we see a static pressure increase in the offset well\n",
    "     - produce a communication event/alert so that the operator can decide whether they want to continue or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "base_path = os.environ['basepath']\n",
    "if base_path not in sys.path:\n",
    "    sys.path.append(base_path)\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import scipy.fft as fft\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "import librosa\n",
    "import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "db.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_relative_sensor_data_file(sensor_id, start_time, end_time, path, environment='staging'):\n",
    "    cmd = os.path.abspath(\"scripts/relative_sensor_data.sh\")\n",
    "    rc = subprocess.call([cmd, sensor_id, start_time, end_time, environment, path],\n",
    "                        stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n",
    "    print(rc)\n",
    "    \n",
    "def load_data(path):\n",
    "    npy = np.load(path)\n",
    "    return npy['arr_0']\n",
    "\n",
    "def relative_sensor_data(sensor_id, start_time, end_time, environment='staging'):\n",
    "    tmp_path = 'data/tmp_data.npz'\n",
    "    download_relative_sensor_data_file(sensor_id, start_time, end_time, tmp_path, environment)\n",
    "    return load_data(tmp_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tmp_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-22fe4ff68b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m new_board_data = relative_sensor_data(\"9c347666-8ed0-4111-989c-89897cbaaced\", \n\u001b[0m\u001b[1;32m      2\u001b[0m                                       \u001b[0;34m\"2020-02-26T21:46:00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2020-02-26T21:50:00\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       \"staging\")\n",
      "\u001b[0;32m<ipython-input-34-4a2935f63f85>\u001b[0m in \u001b[0;36mrelative_sensor_data\u001b[0;34m(sensor_id, start_time, end_time, environment)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtmp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/tmp_data.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdownload_relative_sensor_data_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-4a2935f63f85>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/analytics-upNNx0Fd-py3.8/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tmp_data.npz'"
     ]
    }
   ],
   "source": [
    "new_board_data = relative_sensor_data(\"9c347666-8ed0-4111-989c-89897cbaaced\", \n",
    "                                      \"2020-02-26T21:46:00\", \"2020-02-26T21:50:00\", \n",
    "                                      \"staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_cols(table):\n",
    "    return db.query(f\"\"\"SELECT *\n",
    "  FROM information_schema.columns\n",
    " WHERE table_schema = 'public'\n",
    "   AND table_name   = '{table}';\"\"\")\n",
    "\n",
    "def sensor_info(api):\n",
    "    return db.query(f\"\"\"SELECT sensors.id\n",
    "FROM wells\n",
    "JOIN sensors ON sensors.well_id = wells.id\n",
    "JOIN sensor_models ON sensors.sensor_model_id = sensor_models.id\n",
    "WHERE api = '{api}' AND pressure_type = 'static'\"\"\")\n",
    "\n",
    "def static_sensor_data(sensor_id, start_time, end_time):\n",
    "    return db.query_dataframe(f\"\"\"SELECT max FROM sensor_data where sensor_id = '{sensor_id}' AND time BETWEEN '{start_time}' AND '{end_time}' ORDER BY time ASC\"\"\")\n",
    "\n",
    "def name_to_api(name, number):\n",
    "    return db.query(f\"\"\"select api from wells where wells.name like '%{name}%' AND number = '{number}'\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = name_to_api(\"BRISCOE CATARINA\", \"33HU\")[0][0]\n",
    "sensor_id = sensor_info(api)[0][0]\n",
    "start_time = datetime.datetime(year=2020, month=1, day=8, hour=0, minute=0, second=0).isoformat()\n",
    "end_time = datetime.datetime(year=2020, month=1, day=8, hour=23, minute=59, second=0).isoformat()\n",
    "static_data = static_sensor_data(sensor_id, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_avg(sample, avg, w):\n",
    "    return w*sample + (1-w)*avg\n",
    "\n",
    "def edge_detect(data, threshold):\n",
    "    '''Detect edges that pass through a threshold value.'''\n",
    "    fast_avg = data[0]\n",
    "    slow_avg = data[0]\n",
    "    prev_diff = 0\n",
    "    fa = np.empty_like(data)\n",
    "    sa = np.empty_like(data)\n",
    "    edges = np.empty_like(data, dtype=bool)\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        fast_avg = exp_avg(sample, fast_avg, 0.25)\n",
    "        fa[i] = fast_avg\n",
    "        slow_avg = exp_avg(sample, slow_avg, 0.0625)\n",
    "        sa[i] = slow_avg\n",
    "        diff = abs(fast_avg - slow_avg)\n",
    "        is_edge = prev_diff < threshold and diff >= threshold\n",
    "        edges[i] = is_edge\n",
    "        prev_diff = diff\n",
    "\n",
    "    return fa, sa, np.flatnonzero(edges)\n",
    "\n",
    "favg, savg, edges = edge_detect(static_data['max'].values, 600)\n",
    "\n",
    "#np.flatnonzero((data[:-1] < trigger_val) & (data[1:] > trigger_val))+1\n",
    "static_data['slow_avg'] = savg\n",
    "static_data['fast_avg'] = favg\n",
    "start = 400\n",
    "stop = 8000\n",
    "plt.figure()\n",
    "sig = static_data[start:stop]\n",
    "sig['slow_avg'].plot()\n",
    "plt.plot(np.gradient(sig['slow_avg'].values)*100)\n",
    "for edge in edges:\n",
    "    if edge > start and edge < stop:\n",
    "        plt.axvline(edge)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_npys = []\n",
    "hours = [14, 15, 16]\n",
    "for hour in hours:\n",
    "    path = f'data/BRISCOE-CATARINA-WEST_33HU_dynamic_c62e0d73-2b63-4fba-8a6a-fd96466b545d_2020-01-07T{hour}_00_00.000Z.npz'\n",
    "    npy = np.load(path)\n",
    "    dynamic_npys.append(npy['arr_0'])\n",
    "    \n",
    "dynamic_data = np.concatenate(dynamic_npys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = int(len(dynamic_data) / (60 * 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_average(arr, n):\n",
    "    end =  n * int(len(arr)/n)\n",
    "    return np.mean(arr[:end].reshape(-1, n), 1)\n",
    "\n",
    "def windowed_max(arr, n):\n",
    "    end =  n * int(len(arr)/n)\n",
    "    return np.max(arr[:end].reshape(-1, n), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data_secs = windowed_max(dynamic_data, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
    "\n",
    "\n",
    "def _db_to_amp(x,):\n",
    "    return librosa.core.db_to_amplitude(x, ref=1.0)\n",
    "\n",
    "\n",
    "def plot_spectrogram(signal, title):\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    cax = ax.matshow(\n",
    "        signal,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        cmap=plt.cm.seismic,\n",
    "        vmin=-1 * np.max(np.abs(signal)),\n",
    "        vmax=np.max(np.abs(signal)),\n",
    "    )\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_statistics_and_filter(\n",
    "    mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n",
    "):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(20, 4))\n",
    "    plt_mean, = ax[0].plot(mean_freq_noise, label=\"Mean power of noise\")\n",
    "    plt_std, = ax[0].plot(std_freq_noise, label=\"Std. power of noise\")\n",
    "    plt_std, = ax[0].plot(noise_thresh, label=\"Noise threshold (by frequency)\")\n",
    "    ax[0].set_title(\"Threshold for mask\")\n",
    "    ax[0].legend()\n",
    "    cax = ax[1].matshow(smoothing_filter, origin=\"lower\")\n",
    "    fig.colorbar(cax)\n",
    "    ax[1].set_title(\"Filter for smoothing Mask\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def removeNoise(\n",
    "    audio_clip,\n",
    "    noise_clip,\n",
    "    n_grad_freq=2,\n",
    "    n_grad_time=4,\n",
    "    n_fft=2048,\n",
    "    win_length=2048,\n",
    "    hop_length=512,\n",
    "    n_std_thresh=1.5,\n",
    "    prop_decrease=1.0,\n",
    "    verbose=False,\n",
    "    visual=False,\n",
    "):\n",
    "    \"\"\"Remove noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        visual (bool): Whether to plot the steps of the algorithm\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "    # STFT over noise\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n",
    "    # Calculate statistics over noise\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # STFT over signal\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # Calculate value to mask dB to\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    print(noise_thresh, mask_gain_dB)\n",
    "    # Create a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "    )\n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    # calculate the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(\n",
    "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "        np.shape(sig_stft_db)[1],\n",
    "        axis=0,\n",
    "    ).T\n",
    "    # mask if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # convolve the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # mask the signal\n",
    "    sig_stft_db_masked = (\n",
    "        sig_stft_db * (1 - sig_mask)\n",
    "        + np.ones(np.shape(mask_gain_dB)) * mask_gain_dB * sig_mask\n",
    "    )  # mask real\n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (\n",
    "        1j * sig_imag_masked\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # recover the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
    "    if visual:\n",
    "        plot_spectrogram(noise_stft_db, title=\"Noise\")\n",
    "    if visual:\n",
    "        plot_statistics_and_filter(\n",
    "            mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter\n",
    "        )\n",
    "    if visual:\n",
    "        plot_spectrogram(sig_stft_db, title=\"Signal\")\n",
    "    if visual:\n",
    "        plot_spectrogram(sig_mask, title=\"Mask applied\")\n",
    "    if visual:\n",
    "        plot_spectrogram(sig_stft_db_masked, title=\"Masked signal\")\n",
    "    if visual:\n",
    "        plot_spectrogram(recovered_spec, title=\"Recovered spectrogram\")\n",
    "    return recovered_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a region of the data that is just noise\n",
    "\n",
    "#output = removeNoise(audio_clip=audio_clip_band_limited, noise_clip=noise_clip,verbose=True,visual=True)\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "# plt.plot(output, color='black')\n",
    "# ax.set_xlim((0, len(output)))\n",
    "# plt.show()\n",
    "# # play back a sample of the song\n",
    "# IPython.display.Audio(data=output, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft=2048\n",
    "win_length=2048\n",
    "hop_length=512\n",
    "y = dynamic_data[:600 * sampling_rate]\n",
    "\n",
    "# n_fft (int): number audio of frames between STFT columns.\n",
    "# win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "# hop_length (int):number audio of frames between STFT columns.\n",
    "y_spectrum = _stft(y, n_fft, hop_length, win_length)\n",
    "y_spectrum_db = _amp_to_db(np.abs(y_spectrum))  # convert to dB\n",
    "plot_spectrogram(y_spectrum_db, title=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(xn, cutoff_freq, sampling_rate=40000):\n",
    "    # Create a highpass butterworth filter at 150 Hz\n",
    "    filter_order = 10\n",
    "    sos = signal.butter(filter_order, cutoff_freq, btype='highpass', fs=sampling_rate, output='sos')\n",
    "    y = signal.sosfilt(sos, xn)\n",
    "    return y\n",
    "\n",
    "#     size = len(times)\n",
    "#     offset = 0.0\n",
    "#     portion = 0.1\n",
    "#     a = int(offset * size)\n",
    "#     b = int((offset + portion) * size)\n",
    "#     n = b - a\n",
    "    \n",
    "def plot_spectrogram(times, freqs, spectrums, gamma=0.3):\n",
    "    min_v = spectrums.min()\n",
    "    max_v = spectrums.max()\n",
    "    vmin = 0.0\n",
    "    vmax = 2000.0\n",
    "    fig, ax = plt.subplots(figsize=(24,4))\n",
    "    #normalizer = colors.Normalize(vmin=vmin,vmax=vmax)\n",
    "    #normalizer = colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "    normalizer = colors.PowerNorm(gamma=gamma)\n",
    "    pcm = ax.pcolormesh(times[a:b], freqs, spectrums[:,:n],\n",
    "                        norm=normalizer,\n",
    "                        cmap='Spectral')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    fig.colorbar(pcm)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectrogram_b(signal, grid=True):\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    cax = ax.matshow(\n",
    "        signal,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        cmap=plt.cm.spectral,\n",
    "        vmin=-1 * np.max(np.abs(signal)),\n",
    "        vmax=np.max(np.abs(signal)),\n",
    "    )\n",
    "    plt.grid(grid)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "def spectrogram(xn, sampling_rate=40000):\n",
    "    window_size = 1024\n",
    "    overlap = window_size / 4\n",
    "    scaling = 'spectrum' # 'density' or 'spectrum'\n",
    "    mode = 'magnitude'\n",
    "    freqs, times, spectrums = signal.spectrogram(xn, sampling_rate, \n",
    "                                                 nperseg=window_size, noverlap=overlap, \n",
    "                                                 return_onesided=True, scaling=scaling, mode=mode)\n",
    "    return freqs, times, spectrums\n",
    "\n",
    "def find_peaks(xn, min_prominence=30, min_spacing=2):\n",
    "    peaks, props = signal.find_peaks(y, prominence=min_prominence, distance=min_spacing)\n",
    "    return peaks\n",
    "\n",
    "def plot_peaks(peaks, y):    \n",
    "    plt.plot(peaks, y[peaks], '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 30 * 60 * sampling_rate\n",
    "end = start + (1 * 60 * sampling_rate)\n",
    "xn = dynamic_data[start:end]\n",
    "t = range(len(xn))\n",
    "y = high_pass_filter(xn, 150)\n",
    "#peaks = find_peaks(y)\n",
    "#neg_peaks = find_peaks(-y)\n",
    "pos_peaks, neg_peaks = peakdetect.peakdetect(y, lookahead=80, delta=18)\n",
    "peaks = pos_peaks + neg_peaks\n",
    "freqs, times, spectrums = spectrogram(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original signal and the various filtered versions:\n",
    "plt.figure\n",
    "#plt.grid(True)\n",
    "plt.plot(t, xn, 'blue', alpha=0.1)\n",
    "plt.plot(t, y, 'green',alpha=0.3)\n",
    "plt.plot([x for x,y in peaks], [y for x,y in peaks], '.')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(times, freqs, spectrums / spectrums.max(), gamma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = _amp_to_db(np.abs(spectrums / spectrums.max()))\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "cax = ax.matshow(\n",
    "    sig,\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    "    cmap=plt.cm.Spectral,\n",
    "    vmin=-1 * np.max(np.abs(sig)),\n",
    "    vmax=np.max(np.abs(sig)),\n",
    ")\n",
    "plt.grid(True)\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frac types\n",
    "* created by pressure\n",
    "* created by propping\n",
    "* remain after letting off pressure\n",
    "\n",
    "* Watch the well after the job completes to see what's happening, further fractures or closures, etc.\n",
    "* execution package vs frack optimization package\n",
    "\n",
    "* diagnose when plugs shear, or when guns get stuck\n",
    "* correlate fracture initiation score with static pressure to try to understand whether fractures are long, straight tubes or complex networks that resist flow\n",
    " - the pumps are maintaining a flow rate, not a pressure, so the flow is restricted in complex networks\n",
    "* correlate the frac score with the RTA (rate transient analysis) which is computed after about 120 days\n",
    "\n",
    "\n",
    "* total perforations\n",
    "* perfs per cluster\n",
    "* compartment length\n",
    "* concentration and sand type\n",
    "* volume\n",
    "* chemicals\n",
    "* fluid type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(peaks, y[peaks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft=2048\n",
    "win_length=2048\n",
    "hop_length=512\n",
    "\n",
    "# n_fft (int): number audio of frames between STFT columns.\n",
    "# win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "# hop_length (int):number audio of frames between STFT columns.\n",
    "y_spectrum = _stft(y, n_fft, hop_length, win_length)\n",
    "y_spectrum_db = _amp_to_db(np.abs(y_spectrum))  # convert to dB\n",
    "plot_spectrogram(y_spectrum_db, title=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
    "# >>> plt.title(\"Histogram with 'auto' bins\")\n",
    "# Text(0.5, 1.0, \"Histogram with 'auto' bins\")\n",
    "# >>> plt.show()\n",
    "counts, bin_edges = np.histogram(spectrums, bins=100)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(bin_edges[2:], counts[1:])\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
